[
  {
    "title": "Large Language Models for Code: Security Hardening and Adversarial Testing",
    "authors": "Jingxuan He and Martin Vechev",
    "year": "2023",
    "artifactUrls": [
      "https://arxiv.org/pdf/2302.05319.pdf"
    ],
    "tasks": [
      "Vulnerability Detection",
      "Vulnerability Repair",
      "Adversarial Testing"
    ],
    "featuredModels": [
      "CodeGen",
      "SVEN"
    ]
  },
  {
    "title": "REEF: A Framework for Collecting Real-World Vulnerabilities and Fixes",
    "authors": "Chaozheng Wang and Zongjie Li and Yun Peng and Shuzheng Gao and Sirong Chen and Shuai Wang and Cuiyun Gao and Michael R. Lyu",
    "year": "2023",
    "artifactUrls": [
      "https://arxiv.org/pdf/2309.08115.pdf"
    ],
    "tasks": [
      "Vulnerability Detection"
    ],
    "featuredModels": [
      "GPT-3.5",
      "GPT-4",
      "LLAMA",
      "Vicuna",
      "ChatGLM",
      "Tongyi",
      "GPT-Neo"
    ]
  },
  {
    "title": "Broken Promises: Measuring Confounding Effects in Learning-based Vulnerability Discovery",
    "authors": "Erik Imgrund and Tom Ganz and Martin H\u00e4rterich and Lukas Pirch and Niklas Risse and Konrad Rieck",
    "year": "2023",
    "artifactUrls": [
      "https://www.mlsec.org/docs/2023-aisec.pdf"
    ],
    "tasks": [
      "Vulnerability Detection"
    ],
    "featuredModels": [
      "Code T5+",
      "LineVuln"
    ]
  },
  {
    "title": "Not The End of Story: An Evaluation of ChatGPT-Driven Vulnerability Description Mappings",
    "authors": "Erik Imgrund and Tom Ganz and Martin H\u00e4rterich and Lukas Pirch and Niklas Risse and Konrad Rieck",
    "year": "2023",
    "artifactUrls": [
      "https://aclanthology.org/2023.findings-acl.229.pdf"
    ],
    "tasks": [
      "Vulnerability Mapping"
    ],
    "featuredModels": [
      "Davinci",
      "GPT-3.5"
    ]
  },
  {
    "title": "VulLibGen: Identifying Vulnerable Third-Party Libraries via Generative Pre-Trained Mode",
    "authors": "Tianyu Chen and Lin Li and Liuchuan Zhu and Zongyang Li and Guangtai Liang and Ding Li and Qianxiang Wang and Tao Xie",
    "year": "2023",
    "artifactUrls": [
      "https://arxiv.org/pdf/2308.04662.pdf"
    ],
    "tasks": [
      "Vulnerability Detection"
    ],
    "featuredModels": [
      "LLAMA"
    ]
  },
  {
    "title": "Enhancing Large Language Models for Secure Code Generation: A Dataset-driven Study on Vulnerability Mitigation",
    "authors": "Tianyu Chen and Lin Li and Liuchuan Zhu and Zongyang Li and Guangtai Liang and Ding Li and Qianxiang Wang and Tao Xie",
    "year": "2023",
    "artifactUrls": [
      "https://arxiv.org/pdf/2310.16263.pdf"
    ],
    "tasks": [
      "Vulnerability Detection",
      "Program Repair",
      "Vulnerability Classification"
    ],
    "featuredModels": [
      "GPT-3.5",
      "Starcoder",
      "LaMDA",
      "InCoder"
    ]
  },
  {
    "title": "Software Vulnerability Detection using Large Language Models",
    "authors": "Purba, Moumita Das and Ghosh, Arpita and Radford, Benjamin J. and Chu, Bill",
    "year": "2023",
    "artifactUrls": [
      "https://ieeexplore.ieee.org/document/10301302"
    ],
    "tasks": [
      "Vulnerability Detection"
    ],
    "featuredModels": [
      "GPT-3.5",
      "GPT-4"
    ]
  },
  {
    "title": "How well does LLM generate security tests?",
    "authors": "Ying Zhang and Wenjia Song and Zhengjie Ji and Danfeng and Yao and Na Meng",
    "year": "2023",
    "artifactUrls": [
      "https://arxiv.org/pdf/2310.00710.pdf"
    ],
    "featuredModels": [
      "GPT-4"
    ],
    "tasks": [
      "security test case generation"
    ]
  }
]